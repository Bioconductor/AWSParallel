---
title: "AWSParallel AWSBatchJobsParam Tutorial"
author: "Nitesh Turaga"
date: "`r Sys.Date()`"
output:
  BiocStyle::html_document:
    number_sections: yes
    theme: united
    toc_float: yes
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction

The AWSParallel package provides functionality to perform parallel
evaluation using AWS infrastructure, most importantly EC2. It also
internally uses `StarCluster` to deploy jobs on SGE. It extends
`BatchJobsParam` class in BiocParallel, and works with the same range of R
and Bioconductor objects as `BatchJobsParam`.

The goal of the AWSParallel package is allow the user to create a cluster
of EC2 machines on AWS, and run `bplapply` from one "master" node (EC2
instance) to submit jobs to a set of "worker" nodes (multiple EC2
instances). It is important to note that, both master and worker nodes are
AWS EC2 machines. A side-effect of the way we configure the required
software to enable batch job submission is, the "master" and "workers"
which act as the cluster, need to be spawned (started) from a Bioconductor
AMI.  The user will have to start an instance, manually, and use this
machine as cluster starter (primary machine where AWSParallel is being
run).

This package requires that the user have an Amazon AWS account that **costs
money** and requires a credit card to access. The AWS credentials provided
by the user also need access, to other AWS services as well, namely,

    1. IAM
    2. VPC
    3. EC2

We leave the responsibility to the user to figure out AWS, although many
helpful tutorials are pointed out in the *References* section.

# Quick Start

The quick start guide assumes you have your AWS access key, and secret key
in `~/.aws/credentials`. Please refer to the detailed section of the
vignette if these settings are not present. We are expecting at this point,
that you have launched the AMI (FIXME: INSERT AMI NUMBER HERE) provided by Bioconductor.

You have to use the AMI created by Bioconductor, which includes starcluster
and Bioc-devel to use this package. This will be your **HOST** instance

Load the **AWSParallel** library and create an `AWSBatchJobsParam` object. This
step is needed to **setup** your cluster on AWS.

```{r, eval=FALSE}
library(AWSParallel)

# Number of workers
workers = 2

## AMI required for correct configuration (Bioc-devel with starcluster)
image <- "ami-5121052b"

## The AWS credntials are needed on the AMI as well. They need to be
## in the default location, or the path needs to be specified.
credentialsPath = "~/.aws/credentials"

## Specify the instance type of your AWS Cluster, the same instance type
## will apply to your master and workers. Usually 
instanceType = "t2.micro"

## Subnet you want to use from your AWS account.
subnet <- "subnet-d66a05ec"

## SSH key pair
awsSshKeyPair = getOption("aws_ssh_key_pair")

## If you don't have a key you use, just create a new one
## for AWSParallel, and use that throughout.
keyPair <- "mykey"

## Launch a small instance for demonstration `t2.micro`,
## larger instances cost more money.

## Construct AWSBatchJobsParam class
aws <- AWSBatchJobsParam(workers = workers,
                  awsCredentialsPath = credentialsPath,
                  awsInstanceType = instanceType,
                  awsSubnet = subnet,
                  awsAmiId = image,
                  awsSshKeyPair = keyPair,
                  awsProfile="default")

aws
```

Start, use, and stop a cluster.

```{r awsDetectMaster, eval=FALSE, echo=FALSE}
## This is a conditional param used to evaluate the vignette
awsDetectMaster <- function()
{
        ## Get list of all instances on AWS account
    instances <- aws.ec2::describe_instances()
    ## Get hostname of local machine code is being run on
    hostname <- system2("hostname", stdout=TRUE)
    hostname <- gsub("-",".", sub("ip-","", hostname))
    bool <- FALSE
    for (i in seq_along(instances)) {
        instancesSet = instances[[i]][["instancesSet"]]
        for (j in seq_along(instancesSet)) {
            privateIpAddress <- instancesSet[[j]][["privateIpAddress"]]
            if (privateIpAddress == hostname) {
                bool <- TRUE
            }
        }
    }
    bool
}

onMaster <- awsDetectMaster()
```

We now should start an AWS Cluster from our HOST instance. The setup step 
usually takes a few mins to start the cluster. The code chunk below shows you 
the functionality of controlling the AWS Cluster from the HOST node. 

You can **setup** an AWS cluster with a master and a few workers using
`bpsetup()`. Given that our current configuration has `workers=2`, the cluster
contains **1 master** and **1 worker** node. This step produces quite a bit of
verbose output about the launch of your cluster (don't be alarmed).

You can **suspend** the AWS cluster using `bpsuspend()`, this stops your AWS
cluster but does not terminate the instances in the cluster.

You can **teardown** or terminate the AWS cluster using `bpteardown()`, this
will terminate your AWS cluster and remove any data on the master or worker
nodes that are not saved. You should use this option with caution.

## Setup AWS Cluster

```{r conditional, eval=FALSE}

## Setup AWS cluster (takes a few mins)
bpsetup(aws)
```

```{r, eval=FALSE}
## Suspend AWS cluster, this command is not being run.
bpsuspend(aws)

## Terminate or teardown AWS cluster, this command is not being run.
bpteardown(aws)
```

Once the cluster is setup, you should log into your master node of you AWS 
cluster. This can be done using the following step on your host's command line.

_NOTE_: This is not an R command, you need to exit your R session and use this 
command once your AWS Cluster has successfully launched. If this command fails,
then your key has not been setup properly or the previous previous commands 
haven't been used correctly.

```
starcluster sshmaster -u ubuntu awsparallel
```

Once you have logged into your **master** node, you may launch your jobs on
the cluster. Start a new R session,

```{r, eval=FALSE}
## Load the AWSParallel library
library(AWSParallel)

## Get the AWSBatchJobsParam which is already registered on your master node
aws <- registered()[[1]]

## Test the bplapply command with some function, this function 
## just prints out the hostname of the machine.
FUN <- function(i) system("hostname", intern=TRUE)

## Run a bplapply command with FUN, set the BPPARAM to aws
## This will submit jobs to your AWS cluster
xx <- bplapply(1:100, FUN, BPPARAM = aws)

## See the hostname of your cluster and how the jobs have been divided.
table(unlist(xx))
```

Once you are done with submitting jobs on the AWS cluster, you need to suspend,
or teardown, to avoid being charged by amazon when it is not in use. This is done
on the HOST machine again.

```{r, eval=FALSE}
bpteardown(aws)
```

# AWS settings

Settings required to get the package working on AWS.

## Get AWS Credntials

To use AWSParallel, AWS credentials are a requirement. The credentials
are given through [AWS Identity and Access management - IAM][]. The
user needs an AWS access key and an AWS secret key.

These AWS credntials should be stored on your machine accessible at
`~/.aws/credentials`, as given in the documentation for
[configuring AWS credentials][].

Example AWS credentials, which need to be in the file,
"~/.aws/credentials".


    [default]
    aws_access_key_id=AKIAIOSFODNN7EXAMPLE
    aws_secret_access_key=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY


The AWS credentials provided to the package need access to a few
components of the AWS account,

1. IAM - This is used to get the credentials, change credentials,
   activate/deactivate credentials for security reasons.
1. VPC - This is used to detect VPC's in the region, so that all the
   instances launched are within the same VPC, and same subnet.
1. EC2 - This is used to launch, run, and terminate instances as
   needed.

## AWS Key Pair

User's also need to create a KeyPair which needs to be accessible on
the machine being used. The Key Pair can be created using the
[AWS-EC2 interface][].

It can also be done programmatically using the `AWSParallel` package
but the functionality is imported from `aws.ec2`.

```{r eval=FALSE}
library(AWSParallel)
## Use credentials in your ~/.aws/crentials file
aws.signature::use_credentials()
## This saves the `.pem` file in your your path ~/AWSParallel-keypair.pem
aws.ec2::create_keypair(
    keypair = "AWSParallel-key", path="~/AWSParallel-keypair.pem"
)

## Key pair to be passed in to your AWSSnowParam class
awsSshKeyPair = "~/AWSParallel-keypair.pem"
```

## VPC and Subnet (Optional)

Every AWS account has a default *VPC* created when the account is
started. This VPC is usually contained to one AWS Region. Most of the
Bioconductor AMI's are located on the *AWS-Region US-EAST*, so
starting your account with a VPC located in that region makes most
sense.

If the VPC is created(by the user or amazon default), the account gets
*Subnets* as well by default. For the `AWSSnowParam` class to be
created, the user has to specify the Subnet. If the subnet is not
given, we use, the first one on the AWS account.

*NOTE:* The *master* instance and the *worker* instances need to be on
the same VPC and subnet with permissible security groups. Without this
the socket connection established with other machines launched on AWS
does not work well.

## Security Group settings (Optional)

Security groups are probably the most important AWS setting required
in AWSParallel. It's easier if

![Security Group Inbound Rules](inbound_rules.png)

![Security Group Outbound Rules](outbound_rules.png)


Once you have the following AWS components set up, you are ready to
use the package

# Working with the package AWSParallel

We need to launch the Bioconductor AMI for the *release* version. Do
this by creating an `AWSSnowParam` object

FIXME: this code chunk should be written to be evaluated

```{r, eval = FALSE}
## Load the package
library(AWSParallel)

## bioc-release 3.6 as found in https://www.bioconductor.org/config.yaml
image <- "ami-a90c23cc"

## Number of workers to be started in the AWS cluster
workers = 4

## Set the AWS SSH key pair for your machine, or
## If you already have a keypair, just set the path_to_key, to the pem file.
path_to_key = "~/aws-parallel.pem"

## TODO: This can also be automated
awsSshKeyPair = aws.ec2::create_keypair("AWSParallelKeyPair", path_to_key)

## 
sg <- "sg-748dcd07"
subnet <- "subnet-d66a05ec"

## Create AWS instance
aws <- AWSSnowParam(
    workers=workers,
    awsInstanceType="t2.micro",
    awsSubnet = subnet,
    awsSecurityGroup = sg,
    awsAmiId= image,
    awsSshKeyPair = path_to_key,
    awsCredentialsPath="/home/ubuntu/credentials"
    )

aws
## Check if instance is up,
awsInstanceStatus(aws)

```

Then perform diagnostics, start, use, and stop the cluster

```{r, eval=FALSE}
## Chunk is supposed to eval onMas
## Start instance
bpstart(aws)

## Return cluster which was started
awsCluster()

## Check is instance is up
awsInstanceStatus(aws)

## start an AWSParam job
bplapply(1:4, function(i) system("hostname", intern=TRUE), BPPARAM=aws)

## Stop aws instance
bpstop(aws)
```

# Choosing AWS EC2 Instance Size

The size of an AWS-EC2 Instance gives you access to the required
amount of compute power. Larger instances usually have a higher
capacity for computing, but also cost more money. The [AWS Pricing][]
is given in the documentation, and we recommend you take a look at it.

The Bioconductor AMI's have been built using the *m4.xlarge*
machine. So ideally to run a large computation, and use every package
available in Bioconductor you would use your worker of size
*m4.xlarge*. If you are using a limited set of packages, or you just
need to run a job in parallel, it would be easier to take a look at
the [Instance types][] and decide the appropriate size for your needs.


# Steps to prepare master instance.

This process can be done ONE time, and the instance can be stopped
without being terminated. This *master* instance can be reused.

1. Create a new amazon EC2 instance which is going to be the *master*
   node, by choosing the AMI-ID from this page,
   http://bioconductor.org/help/bioconductor-cloud-ami/#ami_ids. Follow
   the steps in the ec2 management console to launch the image.

    ![Choose EC2 Instance Type](choose-instance-type.png)

    ![Configure EC2 instance with security settings](configure-instance.png)

    ![Add storage as per usage requirements](add-storage.png)

    You are required to create a Keypair if you don't have one
    already. This can be done using this [AWS-EC2 interface][]
    console.

    ![Review and launch your master instance](review-and-launch.png)

1. Name your master instance. This is important for getting your
   instances settings. Call it "AWSParallelMaster"

1. SSH into the instance, which will be 

        ssh -i ~/.ssh/AWSparallel-test-keypair.pem ubuntu@34.239.248.175
    
1. Once you are logged in, there are a few things you need to set
   up. Install the `AWSParallel` package in your R prompt.

        biocLite(`AWSParallel`)
    
    If you have a dependency error installing AWSParallel, because of
    missing dependencies, i.e `aws.ec2` and `aws.signature`, try

        install.packages(
            "aws.ec2", repos = c(getOption("repos"), 
            "http://cloudyr.github.io/drat")
        )

1. Copy your AWS credentials to this machine, by writing your
   credentials in the `~/.aws/credentials` directory.

1. Copy you AWS SSH keypair file (.pem) file to the machine as
   well. The `.pem` file needs to have permissions to read only, i.e
   run `chmod 400 AWSparallel-test-keypair.pem` if you get a
   permissions error.
   
   
# Instructions for Windows machines.

For windows machines, we recommend that you manually follow the steps to 
prepare a master instance instead of using the `awsLaunchMasterOnEc2` function.

Once you prepare the master instance, and are able to establish an SSH 
connection to the master you may use the rest of the package as described 
without any difference because of the platform.


# Advanced Tips

1. If you choose to keep your cluster isolated from any other work you have 
going on your VPC. Please create a new VPC and use the subnets in that VPC
to start your AWSParallel param.

1. Give the AWSParallel param, the new subnet, and a security group as described
in the security group section.

1. If you want to get the verbose output of the SSH connections being
   attempted to your worker nodes, please use the option
   `verbose=TRUE` when making your AWSSnowParam object.

1. It is important that this cluster configuration is used only to launch parallel
jobs. If you launch a large job on the "master" node, there is no increment in speed.
It is vital that large jobs are not launched on the master node.


# Session Info

```{r}
sessionInfo()
```

[AWS Identity and Access management - IAM]:http://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys

[configuring AWS credentials]:http://docs.aws.amazon.com/cli/latest/userguide/cli-config-files.html

[AWS-EC2 interface]:http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html#having-ec2-create-your-key-pair

[AWS Pricing]:https://aws.amazon.com/ec2/pricing/

[Instance types]: https://aws.amazon.com/ec2/instance-types/
